{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d17e74-957f-4477-a0c8-7da5a651498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939a161-b1ee-403a-838f-20f81dddbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56127f3e-731e-40fd-96fe-a16355399dbf",
   "metadata": {},
   "source": [
    "#sys.path.insert(1, os.path.join(\"C:\\\\\", \"Users\", \"Soham\", \"Desktop\", \"CovNet\", \"source_codes\"))\n",
    "## modify as needed\n",
    "\n",
    "import CovNetworks as CN\n",
    "import Important_functions as Ifn\n",
    "import Other_functions as Ofn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf4a28-ddd1-4ee0-9e18-e077aebae5b7",
   "metadata": {},
   "source": [
    "import current_setup as setup\n",
    "\n",
    "### Update\n",
    "\n",
    "method = input(\"Model [Shallow/Deepshared/Deep]: \")\n",
    "if method.lower() == 'deepshared' or method.lower() == 'deep':\n",
    "    depth = input(\"Depth of the network: \")\n",
    "    depth = int(depth)\n",
    "R = input(\"Number of components (R): \")\n",
    "R = int(R)\n",
    "\n",
    "act_fn = setup.act_fn\n",
    "init = setup.init\n",
    "#loss = 'COV'\n",
    "loss_fn = Ifn.loss_COV\n",
    "\n",
    "if method.lower()=='shallow':\n",
    "    err_file = 'Err_'+method+'_'+str(R)+'.txt'\n",
    "elif method.lower()=='deepshared' or method.lower() == 'deep':\n",
    "    err_file = 'Err_'+method+'_'+str(depth)+'_'+str(R)+'.txt'\n",
    "\n",
    "dirc = setup.directory\n",
    "replicates = setup.replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9c0c6-ee42-42d4-8f75-e8f18dffe537",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc = \"C:\\\\Soham\\\\Git\\\\spectral-NN\\\\Data\\\\\"\n",
    "repl = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a653e-a3d2-4232-b97f-bcd7ee68f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('Example'+str(repl+1)+':')\n",
    "    file = dirc+'locations'+str(repl+1)+'.dat'\n",
    "    u = np.loadtxt(dirc+\"locations.dat\",dtype=\"float32\")\n",
    "    if len(u.shape)==1:\n",
    "        D, d = len(u), 1\n",
    "        u = u.reshape(D,1)\n",
    "    else:\n",
    "        D, d = u.shape\n",
    "    u = torch.from_numpy(u)\n",
    "    file = dirc+'Example'+str(repl+1)+'.dat'\n",
    "    x = np.loadtxt(file,dtype='float32')\n",
    "    N = x.shape[0]\n",
    "    if x.shape[1] != D:\n",
    "        exit('Data shape mismatch!! Aborting..')\n",
    "    print('N='+str(N)+', D='+str(D)+', d='+str(d))\n",
    "\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x - torch.mean(x,dim=0,keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850ef16-b49e-4e25-b46b-9c7bdee0126e",
   "metadata": {},
   "source": [
    "for repl in replicates:\n",
    "    print('Example'+str(repl+1)+':')\n",
    "    file = dirc+'locations'+str(repl+1)+'.dat'\n",
    "    u = np.loadtxt(file,dtype='float32')\n",
    "    D, d = u.shape\n",
    "    u = torch.from_numpy(u)\n",
    "    file = dirc+'Example'+str(repl+1)+'.dat'\n",
    "    x = np.loadtxt(file,dtype='float32')\n",
    "    N = x.shape[0]\n",
    "    if x.shape[1] != D:\n",
    "        exit('Data shape mismatch!! Aborting..')\n",
    "    print('N='+str(N)+', D='+str(D)+', d='+str(d))\n",
    "    \n",
    "    x = torch.from_numpy(x)\n",
    "    #x = x - torch.mean(x,dim=0,keepdim=True)\n",
    "\n",
    "    if method.lower()=='shallow':\n",
    "        epochs = setup.epochs_shallow\n",
    "        burn_in = setup.burn_in_shallow\n",
    "        interval = setup.interval_shallow\n",
    "        model = CN.CovNetShallow(d,N,R,act_fn,init)\n",
    "        checkpoint_file = 'Best_'+method+'_'+str(R)+'.pt'\n",
    "    elif method.lower()=='deepshared':\n",
    "        epochs = setup.epochs_deepshared\n",
    "        burn_in = setup.burn_in_deepshared\n",
    "        interval = setup.interval_deepshared\n",
    "        model = CN.CovNetDeepShared(d,N,R,depth,act_fn,init)\n",
    "        checkpoint_file = 'Best_'+method+'_'+str(depth)+'_'+str(R)+'.pt'\n",
    "    elif method.lower()=='deep':\n",
    "        epochs = setup.epochs_deep\n",
    "        burn_in = setup.burn_in_deep\n",
    "        interval = setup.interval_deep\n",
    "        n_nodes = R\n",
    "        model = CN.CovNetDeep(d,N,R,depth,n_nodes,act_fn,init)\n",
    "        checkpoint_file = 'Best_'+method+'_'+str(depth)+'_'+str(R)+'.pt'\n",
    "        \n",
    "    optimizer = setup.optimizer(model.params,lr=setup.lr)\n",
    "    split = setup.split\n",
    "    \n",
    "    print(time.ctime())\n",
    "    l_tr, l_va, epoch = Ifn.cnet_optim_best(x,u,model,loss_fn,optimizer,split,epochs,burn_in,interval,checkpoint_file)\n",
    "    del x,u\n",
    "    \n",
    "    file = dirc+'True_locations'+str(repl+1)+'.dat'\n",
    "    loc = np.loadtxt(file,dtype='float32')\n",
    "    u = torch.from_numpy(loc[:,:d])\n",
    "    v = torch.from_numpy(loc[:,d:])\n",
    "    del loc\n",
    "    cov_file = dirc+'True_cov'+str(repl+1)+'.dat'\n",
    "    err = Ofn.cnet_error_MC(model,u,v,cov_file)\n",
    "    \n",
    "    f_Err = open(err_file,'a')\n",
    "    f_Err.write('Example{}:\\n' .format(repl+1))\n",
    "    f_Err.write('Error = {:.10f}\\n' .format(err))\n",
    "    f_Err.write('Number of epochs = {}\\n' .format(epoch))\n",
    "    f_Err.close()\n",
    "    print('Error = {:.6f}'.format(err))\n",
    "    print('Number of epochs = {}' .format(epoch))\n",
    "    print(time.ctime())\n",
    "    print('\\n')\n",
    "    os.remove(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d5272-b25f-4cb7-90c2-25ec32caca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcecfa3e-3029-4369-ad73-daa1fc2da1e7",
   "metadata": {},
   "source": [
    "### Old implementation\n",
    "### Slower\n",
    "\n",
    "\"\"\"\n",
    "class spectralNNShallow(torch.nn.Module):\n",
    "    def __init__(self,N,d,M,L,act_fn=torch.nn.Sigmoid(),init=torch.nn.init.xavier_normal_):\n",
    "        super(spectralNNShallow, self).__init__()\n",
    "        self.N = N\n",
    "        self.L = L\n",
    "        self.act_fn = act_fn\n",
    "        self.init = init\n",
    "        self.weight = torch.zeros([M,2*L+1,d],dtype=torch.float32,requires_grad=True) #weights of the shallow networks\n",
    "        self.bias = torch.zeros([M,2*L+1,1],dtype=torch.float32,requires_grad=True) #biases of the shallow networks\n",
    "        self.xi = torch.zeros([M,N+2*L],dtype=torch.float32,requires_grad=True) #the multipliers xi_{m,h}\n",
    "        self.init(self.weight)\n",
    "        self.init(self.xi)\n",
    "        self.params = list([self.weight, self.xi, self.bias])\n",
    "        ### add bias term\n",
    "\n",
    "    def first_step(self, u):\n",
    "        return self.act_fn(torch.einsum(\"ijk,lk -> ijl\", self.weight, u) + self.bias) #an object of size M x 2L+1 x D\n",
    "\n",
    "    def forward(self, u):\n",
    "        D = u.shape[0]\n",
    "        x_hat = torch.zeros([self.N,D],dtype=torch.float32,requires_grad=False)\n",
    "        for i in range(N):\n",
    "            x_hat[i,:] = torch.einsum(\"ij,ijk -> k\", self.xi[:,i:(i+2*self.L+1)], self.first_step(u))\n",
    "        return x_hat\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40cbe2-7adf-49c3-910f-532da9227e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spectralNNShallow(torch.nn.Module):\n",
    "    def __init__(self,N,d,M,L,act_fn=torch.nn.Sigmoid(),init=torch.nn.init.xavier_normal_):\n",
    "        super(spectralNNShallow, self).__init__()\n",
    "        self.N = N\n",
    "        self.L = L\n",
    "        self.act_fn = act_fn\n",
    "        self.init = init\n",
    "        self.weight = torch.zeros([M,2*L+1,d],dtype=torch.float32,requires_grad=True) #weights of the shallow networks\n",
    "        self.bias = torch.zeros([M,2*L+1,1],dtype=torch.float32,requires_grad=True) #biases of the shallow networks\n",
    "        self.xi = torch.zeros([M,N+2*L],dtype=torch.float32,requires_grad=True) #the multipliers xi_{m,h}\n",
    "        self.init(self.weight)\n",
    "        self.init(self.xi)\n",
    "        self.params = list([self.weight, self.xi, self.bias])\n",
    "        ### add bias term\n",
    "\n",
    "    def first_step(self, u):\n",
    "        return self.act_fn(torch.einsum(\"ijk,lk -> ijl\", self.weight, u) + self.bias) #an object of size M x 2L+1 x D\n",
    "\n",
    "    def iter_prod(self, i, G): ## iterated product with the coefficients in xi\n",
    "        return torch.einsum(\"ij,ijk -> k\", self.xi[:,i:(i+2*self.L+1)], G).reshape(1,-1)\n",
    "\n",
    "    def forward(self, u):\n",
    "        G = self.first_step(u)\n",
    "        return torch.cat([model.iter_prod(i,G) for i in range(self.N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3c931-a877-4c40-8a3d-3aea34e2ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M = 10\n",
    "#L = 10\n",
    "#N = 200\n",
    "#d = 1\n",
    "#K = 100\n",
    "#D = K**d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cc963-a3dc-4526-b29f-9e61bb788bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(np.random.randn(N,D),dtype=\"float32\")\n",
    "#u = np.array(np.arange(1,K+1)/(K+1),dtype=\"float32\").reshape(-1,1)\n",
    "#print(x.shape)\n",
    "#print(u.shape)\n",
    "#x = torch.from_numpy(x)\n",
    "#u = torch.from_numpy(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189fe32-a1a3-4f65-bf01-cc76466fdfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spectralNNShallow(N,d,10,4)\n",
    "#print(model.params)\n",
    "#x_hat = model(u)\n",
    "#loss = torch.norm(x-x_hat)\n",
    "#print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05712214-e548-44c5-a316-01c16e4119f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.params,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b93516d-d922-4ab6-b088-29c901d62880",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ffc2f-9fc2-43ce-947c-96f4b3319f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    loss = torch.norm(x-model(u))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6effea-903e-44b0-8f49-25f4da59ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556674f-cbe3-4a51-9544-093fa4979525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8f128-ff27-415a-8321-ee040d232887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06473bf7-8f43-42c6-9282-bf7592a0087a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
